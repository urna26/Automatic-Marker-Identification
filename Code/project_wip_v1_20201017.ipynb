{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Marker auto-detection\n",
    "#### Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data loading and plotting packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model metric packages \n",
    "#from sklearn import cross_validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,roc_curve, auc\n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text pre-processing packages \n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the root data into the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308, 2)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_data=pd.read_csv('E:\\All accumulated folder\\FREELANCE\\clean data\\Assesment File_v1.csv', encoding = 'unicode_escape')\n",
    "root_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversations</th>\n",
       "      <th>Sub_markers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I acknowledge the progress we made in this jou...</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I acknowledge the progress I made in this jour...</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I would like to appreciate your exploration to...</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How would you like acknowledge yourself before...</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If we have covered all you wanted to achieve a...</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Conversations  Sub_markers\n",
       "0  I acknowledge the progress we made in this jou...          8.9\n",
       "1  I acknowledge the progress I made in this jour...          8.9\n",
       "2  I would like to appreciate your exploration to...          8.9\n",
       "3  How would you like acknowledge yourself before...          8.9\n",
       "4  If we have covered all you wanted to achieve a...          8.8"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1    69\n",
       "8.3    40\n",
       "8.2    30\n",
       "8.1    26\n",
       "7.2    16\n",
       "6.6    13\n",
       "8.6    10\n",
       "7.1    10\n",
       "7.7     9\n",
       "8.5     9\n",
       "5.4     7\n",
       "7.5     6\n",
       "7.8     6\n",
       "7.4     5\n",
       "8.7     5\n",
       "7.3     5\n",
       "5.2     5\n",
       "8.4     5\n",
       "7.6     5\n",
       "8.9     4\n",
       "4.3     4\n",
       "4.2     4\n",
       "6.7     4\n",
       "8.8     3\n",
       "5.5     3\n",
       "4.4     2\n",
       "7.9     1\n",
       "6.8     1\n",
       "Name: Sub_markers, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(root_data)\n",
    "\n",
    "root_data[\"Sub_markers\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removing the missing values from free format description\n",
    "\n",
    "root_data=root_data[root_data[\"Conversations\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_data = root_data.astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Removing records which has srong words  in \"Free format Desc\" column\n",
    "\n",
    "# #Strong words-If these words are present then it is a marker word:\n",
    "\n",
    "# strong_words=['Coach', 'client', 'accomplish' 'session' ]\n",
    "\n",
    "# # Removing the strong word records in \"Free format Desc\" column\n",
    "# root_data1=root_data[~root_data['Sub_markers'].str.contains('|'.join(strong_words),case=False)]\n",
    "# print(\"Number of records removed based on strong words are \",root_data.shape[0]-root_data1.shape[0])\n",
    "\n",
    "# # Reset and drop the index \n",
    "# root_data1.reset_index(inplace=True,drop=True)\n",
    "\n",
    "# # Result:Number of records removed based on strong words are  137"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -----------------------------------------------------------------Text Data  Pre-processing-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Removal of punctuations and special characteristics and handling case senitivity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Removal of Special Characters and Punctuations \n",
    "root_data['Free_format_Desc'] = root_data['Conversations'] .str.replace('[^\\w\\s]','')\n",
    "\n",
    "# converting into lower case \n",
    "root_data['Free_format_Desc'] = root_data['Free_format_Desc'].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: Elaborating Abbrevations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class for replace the Abbrevations and spell corrections using word map \n",
    "class WordReplacer(object): \n",
    " \n",
    "    def __init__(self, word_map):\n",
    "            self.word_map = word_map \n",
    "    def replace(self, word): \n",
    "         return self.word_map.get(word, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to replace abbrevations and spell corrections \n",
    "def replace_text(text):\n",
    "    tokenized_text = word_tokenize(text.lower()) \n",
    "    replaced_text=[replacer.replace(word) for word in tokenized_text ]\n",
    "    replaced_text =' '.join(replaced_text)\n",
    "    return replaced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # word map to handle all the abbrevations and spell corrections that occured in metrics in textual data \n",
    "# wordmap={'What do you' : 'What do you want',\n",
    "#          'we want' : 'What do we want',\n",
    "#          'seek' : 'What do you seek',\n",
    "#          'desire' : 'What do you desire',\n",
    "#          'work on' : 'What do you work',\n",
    "#          'talk about' : 'What do you want to talk about',\n",
    "#          'is on your mind to discuss to accomplish' : 'What do you want to discuss to accomplish',\n",
    "#          'achieve' : 'What do you want achieve',\n",
    "#          'aim for' : 'What do you aim for',\n",
    "#          'look forward to as an outcome or goal in the session' : 'What do you want to look forward as an outcome or goal in the session'\n",
    "# # Abbrevations labelling\n",
    "    \n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Replacing observations and spell corrections on \"Free_format_updated\" column\n",
    "# replacer=WordReplacer(wordmap)\n",
    "# root_data1['Free_format_Desc']=root_data1['Free_format_Desc'].apply(replace_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Manual corrections of words which occured in metrics created from text data \n",
    "# root_data1['Free_format_Desc_Updated'] = root_data1['Free_format_Desc_Updated'] .str.replace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: Tokenazation and Removal of Stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of customized stopwords are : 323\n"
     ]
    }
   ],
   "source": [
    "# Sysytem defined stop-words-(Eliminated all negated stopwords(Eg: off,over,doesn't,not etc.,))\n",
    "#sample structure\n",
    "stop_words=stopwords.words('english')\n",
    "rm_stop=['before', 'after', 'above', 'below', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'no',\n",
    "         'nor', 'not', 'too', 'very', \"don't\", \"aren't\", \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", \"hadn't\", \"hasn't\",\n",
    "          \"haven't\", \"wasn't\", \"weren't\"]\n",
    "stop_words= [word for word in stop_words if word  not in rm_stop]\n",
    "\n",
    "# user defined stopwords(based on 1 gram analysis)\n",
    "stop_words.extend([#'number', 'plate','paint','presume','pour','car','vehicle','tp','policyholder','policy holder','ph','phv','insured','policy','holder',\n",
    "                   #stopwords from unigrams\n",
    "                   #'tbc','go','ab','tl','ncrc','ahs','fr','cv','nar','ne','xs','lr',\n",
    "\n",
    "                   # Stopwords taken from TFIDF \n",
    "'a','also','although','always','am','among','amongst','amoungst','amount','an','and','another','any','anyhow','anyone',\n",
    "'anything','anyway','anywhere','are','around','as','at','be','became','because','become','becomes','becoming','been','being',\n",
    "'between','bill','but','by','call','cry','de','describe','due','during','each','eg','either','eleven','else','even','ever',\n",
    "'fifteen','fifty','for','former','formerly','forty','from','further','give','go','here','hereafter','hereby','herein','hereupon',\n",
    "'hers','him','his','how','however','i','ie','if','inc','interest','is','it','its','itself','latter','latterly','ltd','made',\n",
    "'may','me','meanwhile','might','mill','mine','my','myself','name','namely','nine','no','noone','now','often','once','our',\n",
    "'perhaps','rather','re','same','see','seem','seemed','seeming','seems','she','show','since','sincere','six','sixty','so',\n",
    "'sometime','sometimes','somewhere','still','such','system','take','ten','that','the','their','them','themselves','then',\n",
    "'thence','there','thereafter','thereby','therefore','therein','thereupon','these','they','third','this','those','thus','twelve',\n",
    "'twenty','un','until','us','was','we','were','what','whatever','when','whence','whenever','where','whereafter','whereas','whereby',\n",
    "'wherein','whereupon','wherever','whether','which','who','whoever','whom','whose','why','will','would','you','your','yours',\n",
    "'yourself','yourselves','in'])\n",
    "\n",
    "print(\"Total number of customized stopwords are :\",len(stop_words))\n",
    "\n",
    "# Result: Total number of customized stopwords are : 337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to replace stopwords \n",
    "def clean_text(text):\n",
    "   \n",
    "    # Tokenization of text\n",
    "    tokenized_text = word_tokenize(text.lower()) \n",
    "    \n",
    "    # Removal of Stop words \n",
    "    cleaned_text =[t for t in tokenized_text if t not in stop_words and re.match('[a-zA-Z\\\\-][a-zA-Z\\\\-]{1,}', t) and t.isalpha()]\n",
    "    #Join all words\n",
    "    cleaned_text =' '.join(cleaned_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replacing Stopwords in \"Free_format_updated\" column\n",
    "root_data['Free_format_Desc']=root_data['Free_format_Desc'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        acknowledge progress journey\n",
       "1                        acknowledge progress journey\n",
       "2    like appreciate exploration aware needed achieve\n",
       "3                       like acknowledge before close\n",
       "4          covered wanted achieve ready close session\n",
       "5            covered wanted today ready close session\n",
       "6                                 ready close session\n",
       "7                                 people turn support\n",
       "8                           coming up helpful actions\n",
       "9                             issues need help action\n",
       "Name: Free_format_Desc, dtype: object"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text before stopword removal and handling abbrevations \n",
    "root_data['Free_format_Desc'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4: Lemmatization of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to perform Lematization\n",
    "lmtzr = WordNetLemmatizer()\n",
    "def clean_text_lemma(text):\n",
    "        \n",
    "    # Tokenization of text\n",
    "    tokenized_text = word_tokenize(text.lower()) \n",
    "    \n",
    "    # Lemmatization\n",
    "    cleaned_text =[lmtzr.lemmatize(t,pos='v') for t in tokenized_text]\n",
    "    \n",
    "    #Joining all words\n",
    "    cleaned_text =' '.join(cleaned_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Performing lematization on \"Free_format_updated\" column\n",
    "root_data['Free_format_Desc']=root_data['Free_format_Desc'].apply(clean_text_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      acknowledge progress journey\n",
       "1                      acknowledge progress journey\n",
       "2    like appreciate exploration aware need achieve\n",
       "Name: Free_format_Desc, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_data['Free_format_Desc'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversations</th>\n",
       "      <th>Sub_markers</th>\n",
       "      <th>Free_format_Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I acknowledge the progress we made in this jou...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>acknowledge progress journey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I acknowledge the progress I made in this jour...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>acknowledge progress journey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I would like to appreciate your exploration to...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>like appreciate exploration aware need achieve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How would you like acknowledge yourself before...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>like acknowledge before close</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If we have covered all you wanted to achieve a...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>cover want achieve ready close session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>If we have covered all you wanted to do today ...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>cover want today ready close session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Are ready to close the session?</td>\n",
       "      <td>8.8</td>\n",
       "      <td>ready close session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Who may the be the people you can turn to for ...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>people turn support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What else is coming up as being helpful for yo...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>come up helpful action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What do you see as issues you may need help wi...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>issue need help action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What do you see as issues you may need help wi...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>issue need help plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What do you think as issues you may need help ...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>think issue need help action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What do you think as issues you may need help ...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>think issue need help plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What do you anticipate as issues you may need ...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>anticipate issue need help action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What do you anticipate as issues you may need ...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>anticipate issue need help plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>As you reflect on actions you wish to take and...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>reflect on action wish step need plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>As you reflect on actions you wish to take and...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>reflect on action wish step need like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>With the high motivation you have given the im...</td>\n",
       "      <td>8.7</td>\n",
       "      <td>high motivation give importance place on outco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>With the high motivation you have given the im...</td>\n",
       "      <td>8.7</td>\n",
       "      <td>high motivation give importance place on outco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>With the high motivation you have given the im...</td>\n",
       "      <td>8.7</td>\n",
       "      <td>high motivation give importance place on outco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>With the high motivation you have given the im...</td>\n",
       "      <td>8.7</td>\n",
       "      <td>high motivation give importance place on outco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>With the high motivation you have given the im...</td>\n",
       "      <td>8.7</td>\n",
       "      <td>high motivation give importance place on outco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Let us see what comes up for you as actions to...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>let come up action work on follow insights ach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>How may you consider acting on what you learn ...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>consider act on learn session later on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>What steps can you think of taking from this r...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>step think take reflection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>What steps can you think of taking from this l...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>step think take learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>From when will you start applying what you hav...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>start apply insights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>From when will you start applying what you hav...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>start apply learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>What else do you plan of doing?</td>\n",
       "      <td>8.5</td>\n",
       "      <td>plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What else do oyu think of doing?</td>\n",
       "      <td>8.5</td>\n",
       "      <td>oyu think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>What would help you to discuss about today</td>\n",
       "      <td>3.1</td>\n",
       "      <td>help discuss today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>What would help you to talk about today</td>\n",
       "      <td>3.1</td>\n",
       "      <td>help talk today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>So, this ",
       ".is what you wish to seek</td>\n",
       "      <td>3.1</td>\n",
       "      <td>wish seek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>So, this ",
       ".is what you wish to desire</td>\n",
       "      <td>3.1</td>\n",
       "      <td>wish desire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>So, this ",
       ".is what you wish to talk about</td>\n",
       "      <td>3.1</td>\n",
       "      <td>wish talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>So, this ",
       ".is what you wish to achieve</td>\n",
       "      <td>3.1</td>\n",
       "      <td>wish achieve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>So, this ",
       ".is what you wish to accomplish</td>\n",
       "      <td>3.1</td>\n",
       "      <td>wish accomplish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Feel free to tell me if my  understanding of w...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>feel free tell understand hear not say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Please correct me if I am wrong</td>\n",
       "      <td>4.4</td>\n",
       "      <td>please correct wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>What else would you like to say</td>\n",
       "      <td>4.3</td>\n",
       "      <td>like say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>What more would you like to say</td>\n",
       "      <td>4.3</td>\n",
       "      <td>like say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Take your time...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Is there anything more to add</td>\n",
       "      <td>4.3</td>\n",
       "      <td>add</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>I hear your feeling ....... about what is happ...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>hear feel happen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Please feel free to share what yiu feel, this ...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>please feel free share yiu feel asafe space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Please feel free to share what yiu think, this...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>please feel free share yiu think asafe space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Please feel free to share what yiu eperince, t...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>please feel free share yiu eperince asafe space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>I hear you saying ..., is this what you think ...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>hear say think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>I observe you saying ..., is this what you thi...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>observe say think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>I notice you saying ..., is this what you thin...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>notice say think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>I hear you saying ..., is this what you think ...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>hear say think others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>I observe you saying ..., is this what you thi...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>observe say think others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>I  notice you saying ..., is this what you thi...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>notice say think others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>I hear you saying ..., is this what you think ...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>hear say think workplace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>I observe you saying ..., is this what you thi...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>observe say think workplace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>I notice you saying ..., is this what you thin...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>notice say think workplace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>What would make you think of others around you...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>make think others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>What would make you think of  your  workplace....</td>\n",
       "      <td>6.6</td>\n",
       "      <td>make think workplace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>What would make you feel difffrently of yourse...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>make feel difffrently workplace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>What would make you feel difffrently of yourse...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>make feel difffrently others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>308 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Conversations Sub_markers  \\\n",
       "0    I acknowledge the progress we made in this jou...         8.9   \n",
       "1    I acknowledge the progress I made in this jour...         8.9   \n",
       "2    I would like to appreciate your exploration to...         8.9   \n",
       "3    How would you like acknowledge yourself before...         8.9   \n",
       "4    If we have covered all you wanted to achieve a...         8.8   \n",
       "5    If we have covered all you wanted to do today ...         8.8   \n",
       "6                      Are ready to close the session?         8.8   \n",
       "7    Who may the be the people you can turn to for ...         8.6   \n",
       "8    What else is coming up as being helpful for yo...         8.6   \n",
       "9    What do you see as issues you may need help wi...         8.6   \n",
       "10   What do you see as issues you may need help wi...         8.6   \n",
       "11   What do you think as issues you may need help ...         8.6   \n",
       "12   What do you think as issues you may need help ...         8.6   \n",
       "13   What do you anticipate as issues you may need ...         8.6   \n",
       "14   What do you anticipate as issues you may need ...         8.6   \n",
       "15   As you reflect on actions you wish to take and...         8.6   \n",
       "16   As you reflect on actions you wish to take and...         8.6   \n",
       "17   With the high motivation you have given the im...         8.7   \n",
       "18   With the high motivation you have given the im...         8.7   \n",
       "19   With the high motivation you have given the im...         8.7   \n",
       "20   With the high motivation you have given the im...         8.7   \n",
       "21   With the high motivation you have given the im...         8.7   \n",
       "22   Let us see what comes up for you as actions to...         8.5   \n",
       "23   How may you consider acting on what you learn ...         8.5   \n",
       "24   What steps can you think of taking from this r...         8.5   \n",
       "25   What steps can you think of taking from this l...         8.5   \n",
       "26   From when will you start applying what you hav...         8.5   \n",
       "27   From when will you start applying what you hav...         8.5   \n",
       "28                     What else do you plan of doing?         8.5   \n",
       "29                    What else do oyu think of doing?         8.5   \n",
       "..                                                 ...         ...   \n",
       "278         What would help you to discuss about today         3.1   \n",
       "279            What would help you to talk about today         3.1   \n",
       "280                So, this \n",
       ".is what you wish to seek         3.1   \n",
       "281              So, this \n",
       ".is what you wish to desire         3.1   \n",
       "282          So, this \n",
       ".is what you wish to talk about         3.1   \n",
       "283             So, this \n",
       ".is what you wish to achieve         3.1   \n",
       "284          So, this \n",
       ".is what you wish to accomplish         3.1   \n",
       "285  Feel free to tell me if my  understanding of w...         4.4   \n",
       "286                    Please correct me if I am wrong         4.4   \n",
       "287                    What else would you like to say         4.3   \n",
       "288                    What more would you like to say         4.3   \n",
       "289                                  Take your time...         4.3   \n",
       "290                     Is there anything more to add          4.3   \n",
       "291  I hear your feeling ....... about what is happ...         4.2   \n",
       "292  Please feel free to share what yiu feel, this ...         4.2   \n",
       "293  Please feel free to share what yiu think, this...         4.2   \n",
       "294  Please feel free to share what yiu eperince, t...         4.2   \n",
       "295  I hear you saying ..., is this what you think ...         6.6   \n",
       "296  I observe you saying ..., is this what you thi...         6.6   \n",
       "297  I notice you saying ..., is this what you thin...         6.6   \n",
       "298  I hear you saying ..., is this what you think ...         6.6   \n",
       "299  I observe you saying ..., is this what you thi...         6.6   \n",
       "300  I  notice you saying ..., is this what you thi...         6.6   \n",
       "301  I hear you saying ..., is this what you think ...         6.6   \n",
       "302  I observe you saying ..., is this what you thi...         6.6   \n",
       "303  I notice you saying ..., is this what you thin...         6.6   \n",
       "304  What would make you think of others around you...         6.6   \n",
       "305  What would make you think of  your  workplace....         6.6   \n",
       "306  What would make you feel difffrently of yourse...         6.6   \n",
       "307  What would make you feel difffrently of yourse...         6.6   \n",
       "\n",
       "                                      Free_format_Desc  \n",
       "0                         acknowledge progress journey  \n",
       "1                         acknowledge progress journey  \n",
       "2       like appreciate exploration aware need achieve  \n",
       "3                        like acknowledge before close  \n",
       "4               cover want achieve ready close session  \n",
       "5                 cover want today ready close session  \n",
       "6                                  ready close session  \n",
       "7                                  people turn support  \n",
       "8                               come up helpful action  \n",
       "9                               issue need help action  \n",
       "10                                issue need help plan  \n",
       "11                        think issue need help action  \n",
       "12                          think issue need help plan  \n",
       "13                   anticipate issue need help action  \n",
       "14                     anticipate issue need help plan  \n",
       "15               reflect on action wish step need plan  \n",
       "16               reflect on action wish step need like  \n",
       "17   high motivation give importance place on outco...  \n",
       "18   high motivation give importance place on outco...  \n",
       "19   high motivation give importance place on outco...  \n",
       "20   high motivation give importance place on outco...  \n",
       "21   high motivation give importance place on outco...  \n",
       "22   let come up action work on follow insights ach...  \n",
       "23              consider act on learn session later on  \n",
       "24                          step think take reflection  \n",
       "25                               step think take learn  \n",
       "26                                start apply insights  \n",
       "27                                   start apply learn  \n",
       "28                                                plan  \n",
       "29                                           oyu think  \n",
       "..                                                 ...  \n",
       "278                                 help discuss today  \n",
       "279                                    help talk today  \n",
       "280                                          wish seek  \n",
       "281                                        wish desire  \n",
       "282                                          wish talk  \n",
       "283                                       wish achieve  \n",
       "284                                    wish accomplish  \n",
       "285             feel free tell understand hear not say  \n",
       "286                               please correct wrong  \n",
       "287                                           like say  \n",
       "288                                           like say  \n",
       "289                                               time  \n",
       "290                                                add  \n",
       "291                                   hear feel happen  \n",
       "292        please feel free share yiu feel asafe space  \n",
       "293       please feel free share yiu think asafe space  \n",
       "294    please feel free share yiu eperince asafe space  \n",
       "295                                     hear say think  \n",
       "296                                  observe say think  \n",
       "297                                   notice say think  \n",
       "298                              hear say think others  \n",
       "299                           observe say think others  \n",
       "300                            notice say think others  \n",
       "301                           hear say think workplace  \n",
       "302                        observe say think workplace  \n",
       "303                         notice say think workplace  \n",
       "304                                  make think others  \n",
       "305                               make think workplace  \n",
       "306                    make feel difffrently workplace  \n",
       "307                       make feel difffrently others  \n",
       "\n",
       "[308 rows x 3 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 5 :Removing the Records of strong words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # # Removing the strong word records in \"free flow text\" column\n",
    "# root_data=root_data[~root_data['Free_format_Desc'].str.contains('|'.join(strong_words),case=False)]\n",
    "# root_data.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -----------------------------------------------------------------------End of Text Data  Pre-Processing------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = root_data.drop(\"Sub_markers\",axis=1)\n",
    "y = root_data[\"Sub_markers\"]\n",
    "X_train, X_val, y_train, y_val=train_test_split(X,y,test_size=.30,random_state=0)\n",
    "# X_train.reset_index(inplace=True,drop=True)\n",
    "# X_val.reset_index(inplace=True,drop=True)\n",
    "# y_train.reset_index(inplace=True,drop=True)\n",
    "# y_val.reset_index(inplace=True,drop=True)\n",
    "\n",
    "# # from sklearn.model_selection import train_test_split\n",
    "# X = root_data.drop(\"Sub_markers\",axis=1)\n",
    "# y = root_data[\"Sub_markers\"]\n",
    "# X, X_test, y, y_test = train_test_split(X_data, y_data, test_size=0.2, train_size=0.8)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X,y,test_size = 0.25,train_size =0.75)\n",
    "# X_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241    3.1\n",
       "237    3.1\n",
       "167    7.4\n",
       "173    7.5\n",
       "291    4.2\n",
       "218    3.1\n",
       "145    7.1\n",
       "261    3.1\n",
       "255    3.1\n",
       "76     8.3\n",
       "156    7.2\n",
       "184    7.7\n",
       "146    7.2\n",
       "166    7.3\n",
       "289    4.3\n",
       "44     8.1\n",
       "182    7.6\n",
       "1      8.9\n",
       "205    NaN\n",
       "111    8.2\n",
       "288    4.3\n",
       "171    7.4\n",
       "120    8.2\n",
       "54     8.1\n",
       "269    3.1\n",
       "18     8.7\n",
       "209    5.4\n",
       "79     8.3\n",
       "159    7.2\n",
       "56     8.1\n",
       "      ... \n",
       "147    7.2\n",
       "283    3.1\n",
       "177    7.5\n",
       "99     8.3\n",
       "197    7.8\n",
       "243    3.1\n",
       "115    8.2\n",
       "265    3.1\n",
       "72     8.3\n",
       "25     8.5\n",
       "165    7.3\n",
       "294    4.2\n",
       "174    7.5\n",
       "296    6.6\n",
       "39     8.1\n",
       "193    7.8\n",
       "88     8.3\n",
       "70     8.3\n",
       "87     8.3\n",
       "292    4.2\n",
       "242    3.1\n",
       "277    3.1\n",
       "211    5.4\n",
       "9      8.6\n",
       "195    7.8\n",
       "251    3.1\n",
       "192    7.8\n",
       "117    8.2\n",
       "47     8.1\n",
       "172    7.5\n",
       "Name: Sub_markers, Length: 215, dtype: object"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LoadingCount vectorizer packages \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # creating object for the TFIDF\n",
    "# vectorizer_tfidf_2_3_gram = TfidfVectorizer(\n",
    "#         ngram_range=(2,3),  # features made of a single tokens\n",
    "#     use_idf=True,  # enable inverse-document-frequency reweighting\n",
    "#     smooth_idf=True,  # prevents zero division for unseen words\n",
    "#     sublinear_tf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Fitting Count Vectoriser on the data \n",
    "# vectorizer_tfidf_2_3_gram.fit(root_data['Free_format_Desc'])\n",
    "\n",
    "# #Transforming on training data \n",
    "# tfidf_2_3_gram=vectorizer_tfidf_2_3_gram.transform(X_train['Free_format_Desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #loading SelectKbest package \n",
    "# from sklearn.feature_selection import SelectKBest\n",
    "# from sklearn.feature_selection import chi2,f_classif,mutual_info_classif\n",
    "\n",
    "# # Creating object for the selectKbest \n",
    "# kselect_2_3_gram=SelectKBest(chi2,k=400)\n",
    "\n",
    "# #Fitting on SelectKbest on Training data\n",
    "# kselect_2_3_gram.fit(tfidf_2_3_gram,y_train)\n",
    "\n",
    "# # #Transforming on training dataset \n",
    "# # tfidf_kbest_2_3_gram=kselect_2_3_gram.transform(tfidf_2_3_gram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of all words from train corpus with their counts.\n",
    "words_counts = {}\n",
    "for comments in X_train:\n",
    "    for word in comments.split():\n",
    "        if word not in words_counts:\n",
    "            words_counts[word] = 1\n",
    "        words_counts[word] += 1\n",
    "        \n",
    "DICT_SIZE = 10000\n",
    "POPULAR_WORDS = sorted(words_counts, key=words_counts.get, reverse=True)[:DICT_SIZE]\n",
    "WORDS_TO_INDEX = {key: rank for rank, key in enumerate(POPULAR_WORDS, 0)}\n",
    "INDEX_TO_WORDS = {index:word for word, index in WORDS_TO_INDEX.items()}\n",
    "ALL_WORDS = WORDS_TO_INDEX.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Conversations', 'Free_format_Desc']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets take a look at top 10 popular words\n",
    "POPULAR_WORDS[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse as sp_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape  (2, 10000) \n",
      "X_val shape  (2, 10000)\n"
     ]
    }
   ],
   "source": [
    "def my_bag_of_words(text, words_to_index, dict_size):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        dict_size: size of the dictionary\n",
    "        \n",
    "        return a vector which is a bag-of-words representation of 'text'\n",
    "    \"\"\"\n",
    "    result_vector = np.zeros(dict_size)\n",
    "    for word in text.split(' '):\n",
    "        if word in words_to_index:\n",
    "            result_vector[words_to_index[word]] +=1\n",
    "    return result_vector\n",
    "\n",
    "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train])\n",
    "X_val_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_val])\n",
    "print('X_train shape ', X_train_mybag.shape, '\\nX_val shape ', X_val_mybag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_features(X_train, X_val, X_test):\n",
    "    \"\"\"\n",
    "        X_train, X_test — samples        \n",
    "        return TF-IDF vectorized representation of each sample and vocabulary\n",
    "    \"\"\"\n",
    "    # Create TF-IDF vectorizer with a proper parameters choice\n",
    "    # Fit the vectorizer on the train set\n",
    "    # Transform the train, test set and return the result\n",
    "    \n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=1.0, min_df=1, token_pattern='(\\S+)')\n",
    "\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "    return X_train_tfidf, X_val_tfidf, X_test_tfidf, tfidf_vectorizer.vocabulary_\n",
    "\n",
    "X_train_tfidf, X_val_tfidf, X_test_tfidf, tfidf_vocab = tfidf_features(X_train, X_val, X_test)\n",
    "tfidf_reversed_vocab = {i:word for word,i in tfidf_vocab.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (0      3.1\n1      3.1\n2      7.4\n3      7.5\n4      4.2\n5      3.1\n6      7.1\n7      3.1\n8      3.1\n9      8.3\n10     7.2\n11     7.7\n12     7.2\n13     7.3\n14     4.3\n15     8.1\n16     7.6\n17     8.9\n18     NaN\n19     8.2\n20     4.3\n21     7.4\n22     8.2\n23     8.1\n24     3.1\n25     8.7\n26     5.4\n27     8.3\n28     7.2\n29     8.1\n      ... \n185    7.2\n186    3.1\n187    7.5\n188    8.3\n189    7.8\n190    3.1\n191    8.2\n192    3.1\n193    8.3\n194    8.5\n195    7.3\n196    4.2\n197    7.5\n198    6.6\n199    8.1\n200    7.8\n201    8.3\n202    8.3\n203    8.3\n204    4.2\n205    3.1\n206    3.1\n207    5.4\n208    8.6\n209    7.8\n210    3.1\n211    7.8\n212    8.2\n213    8.1\n214    7.5\nName: Sub_markers, Length: 215, dtype: object,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-8db9f13c1857>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mclassifier_mybag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_mybag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregularisation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'l2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mclassifier_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregularisation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'l2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-99-8db9f13c1857>\u001b[0m in \u001b[0;36mtrain_classifier\u001b[1;34m(X_train, y_train, C, regularisation)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Create and fit LogisticRegression wraped into OneVsRestClassifier.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregularisation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;31m# overall.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mShape\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0mproblems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \"\"\"\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_input_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: (0      3.1\n1      3.1\n2      7.4\n3      7.5\n4      4.2\n5      3.1\n6      7.1\n7      3.1\n8      3.1\n9      8.3\n10     7.2\n11     7.7\n12     7.2\n13     7.3\n14     4.3\n15     8.1\n16     7.6\n17     8.9\n18     NaN\n19     8.2\n20     4.3\n21     7.4\n22     8.2\n23     8.1\n24     3.1\n25     8.7\n26     5.4\n27     8.3\n28     7.2\n29     8.1\n      ... \n185    7.2\n186    3.1\n187    7.5\n188    8.3\n189    7.8\n190    3.1\n191    8.2\n192    3.1\n193    8.3\n194    8.5\n195    7.3\n196    4.2\n197    7.5\n198    6.6\n199    8.1\n200    7.8\n201    8.3\n202    8.3\n203    8.3\n204    4.2\n205    3.1\n206    3.1\n207    5.4\n208    8.6\n209    7.8\n210    3.1\n211    7.8\n212    8.2\n213    8.1\n214    7.5\nName: Sub_markers, Length: 215, dtype: object,)"
     ]
    }
   ],
   "source": [
    "def train_classifier(X_train, y_train, C, regularisation):\n",
    "    \"\"\"\n",
    "      X_train, y_train — training data\n",
    "      \n",
    "      return: trained classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create and fit LogisticRegression wraped into OneVsRestClassifier.\n",
    "\n",
    "    model = OneVsRestClassifier(LogisticRegression(penalty=regularisation, C=C, max_iter=10000)).fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "classifier_mybag = train_classifier(X_train_mybag, y_train, C = 4, regularisation = 'l2')\n",
    "classifier_tfidf = train_classifier(X_train_tfidf, y_train, C = 4, regularisation = 'l2')\n",
    "\n",
    "y_val_predicted_labels_mybag = classifier_mybag.predict(X_val_mybag)\n",
    "y_val_predicted_labels_tfidf = classifier_tfidf.predict(X_val_tfidf)\n",
    "y_val_predicted_scores_mybag = classifier_mybag.decision_function(X_val_mybag)\n",
    "y_val_predicted_scores_tfidf = classifier_tfidf.decision_function(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversations</th>\n",
       "      <th>Free_format_Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>· What do you/we want to aim for as an outcome...</td>\n",
       "      <td>youwe want aim outcome goal session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>· What do we want to talk about to achieve as ...</td>\n",
       "      <td>want talk achieve outcome goal session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How will ......this help you to look at your s...</td>\n",
       "      <td>help look situation differently</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How will ......this help you to look at yourr ...</td>\n",
       "      <td>help look yourr future life after achieve want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I hear your feeling ....... about what is happ...</td>\n",
       "      <td>hear feel happen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>· What do you seek to accomplish as an outcome...</td>\n",
       "      <td>seek accomplish outcome goal session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What are you learning about yourself in this c...</td>\n",
       "      <td>learn conversation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>· What do we desire to look forward to as an o...</td>\n",
       "      <td>desire look forward outcome goal session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>· What do we want to discuss to aim for as an ...</td>\n",
       "      <td>want discuss aim outcome goal session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How will you use what have you learnt about yo...</td>\n",
       "      <td>use learn situation partner discusions far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What are your values that lead you to feel thi...</td>\n",
       "      <td>value lead feel way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I hear your use of words ..........etc , and y...</td>\n",
       "      <td>hear use word etc expression change sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Is this what you want?</td>\n",
       "      <td>want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>How will your current insights help you look a...</td>\n",
       "      <td>current insights help look youself differently</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Take your time...</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What do you learn about yourself from the our ...</td>\n",
       "      <td>learn share discusions far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Coach's questions are opne, not forcing yes or...</td>\n",
       "      <td>coach question opne not force yes answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I acknowledge the progress I made in this jour...</td>\n",
       "      <td>acknowledge progress journey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>How would you like to like to move forward.......</td>\n",
       "      <td>like like move forward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What do you learn about your situation, from t...</td>\n",
       "      <td>learn situation partner discusions far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What more would you like to say</td>\n",
       "      <td>like say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>How will your current insights help you look a...</td>\n",
       "      <td>current insights help look life differently</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What do you learn about where you are now, fro...</td>\n",
       "      <td>learn share discusions far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What are your awarenes about your abilities af...</td>\n",
       "      <td>awarenes abilities after exploration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>· What do we want to discuss to look forward t...</td>\n",
       "      <td>want discuss look forward outcome goal session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>With the high motivation you have given the im...</td>\n",
       "      <td>high motivation give importance place on outco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>How these relate to the situation you are in?</td>\n",
       "      <td>relate situation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>How will you act upon what have you learnt abo...</td>\n",
       "      <td>act upon learn situation inquiry far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>What are you now thinking now?</td>\n",
       "      <td>think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What are your awareness about your values afte...</td>\n",
       "      <td>awareness value after exploration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Is this what you feel?</td>\n",
       "      <td>feel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>So, this ",
       ".is what you wish to achieve</td>\n",
       "      <td>wish achieve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>How will your current insights help you look a...</td>\n",
       "      <td>current insights help look life differently</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>How will you act upon what have you learnt abo...</td>\n",
       "      <td>act upon learn current reality inquiry far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>What I hear is tht you .. .......how would you...</td>\n",
       "      <td>hear tht like respond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>· What do we seek aim for as an outcome or goa...</td>\n",
       "      <td>seek aim outcome goal session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>What have you learnt about where you are now, ...</td>\n",
       "      <td>learn partner discusions far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>· What do we want to talk about to look forwar...</td>\n",
       "      <td>want talk look forward outcome goal session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>How will you use what have you learnt about  y...</td>\n",
       "      <td>use learn situation conversation far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>What steps can you think of taking from this l...</td>\n",
       "      <td>step think take learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>How will your current learning help you look a...</td>\n",
       "      <td>current learn help look youself differently</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Please feel free to share what yiu eperince, t...</td>\n",
       "      <td>please feel free share yiu eperince asafe space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>What lies beyond your outcome in this session?</td>\n",
       "      <td>lie beyond outcome session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>I observe you saying ..., is this what you thi...</td>\n",
       "      <td>observe say think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>What have you learnt about yourself from the o...</td>\n",
       "      <td>learn share discusions far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>What I sense is tht you .. .......how would yo...</td>\n",
       "      <td>sense tht like respond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>How will you use what have you learnt about yo...</td>\n",
       "      <td>use learn current reality exploration far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>How will you act upon what have you learnt abo...</td>\n",
       "      <td>act upon learn share discusions far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>How will you use what have you learnt about yo...</td>\n",
       "      <td>use learn current reality conversation far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Please feel free to share what yiu feel, this ...</td>\n",
       "      <td>please feel free share yiu feel asafe space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>· What do you seek aim for as an outcome or go...</td>\n",
       "      <td>seek aim outcome goal session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>What do you have on your mind to discuss today?</td>\n",
       "      <td>on mind discuss today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>I am curious to know that based on what is hap...</td>\n",
       "      <td>curious know base on happen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>What do you see as issues you may need help wi...</td>\n",
       "      <td>issue need help action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>What I notice is tht you .. .......how would y...</td>\n",
       "      <td>notice tht like respond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>· What do you to talk about to aim for as an o...</td>\n",
       "      <td>talk aim outcome goal session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>What I think is tht you .. .......how would yo...</td>\n",
       "      <td>think tht like respond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>What do you learn about where you are now, fro...</td>\n",
       "      <td>learn conversation far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>How are you able to align with your inner self?</td>\n",
       "      <td>able align inner self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>How will ......this help you to look at yourr ...</td>\n",
       "      <td>help look yourr future work after achieve want</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Conversations  \\\n",
       "0    · What do you/we want to aim for as an outcome...   \n",
       "1    · What do we want to talk about to achieve as ...   \n",
       "2    How will ......this help you to look at your s...   \n",
       "3    How will ......this help you to look at yourr ...   \n",
       "4    I hear your feeling ....... about what is happ...   \n",
       "5    · What do you seek to accomplish as an outcome...   \n",
       "6    What are you learning about yourself in this c...   \n",
       "7    · What do we desire to look forward to as an o...   \n",
       "8    · What do we want to discuss to aim for as an ...   \n",
       "9    How will you use what have you learnt about yo...   \n",
       "10   What are your values that lead you to feel thi...   \n",
       "11   I hear your use of words ..........etc , and y...   \n",
       "12                             Is this what you want?    \n",
       "13   How will your current insights help you look a...   \n",
       "14                                   Take your time...   \n",
       "15   What do you learn about yourself from the our ...   \n",
       "16   Coach's questions are opne, not forcing yes or...   \n",
       "17   I acknowledge the progress I made in this jour...   \n",
       "18   How would you like to like to move forward.......   \n",
       "19   What do you learn about your situation, from t...   \n",
       "20                     What more would you like to say   \n",
       "21   How will your current insights help you look a...   \n",
       "22   What do you learn about where you are now, fro...   \n",
       "23   What are your awarenes about your abilities af...   \n",
       "24   · What do we want to discuss to look forward t...   \n",
       "25   With the high motivation you have given the im...   \n",
       "26       How these relate to the situation you are in?   \n",
       "27   How will you act upon what have you learnt abo...   \n",
       "28                      What are you now thinking now?   \n",
       "29   What are your awareness about your values afte...   \n",
       "..                                                 ...   \n",
       "185                            Is this what you feel?    \n",
       "186             So, this \n",
       ".is what you wish to achieve   \n",
       "187  How will your current insights help you look a...   \n",
       "188  How will you act upon what have you learnt abo...   \n",
       "189  What I hear is tht you .. .......how would you...   \n",
       "190  · What do we seek aim for as an outcome or goa...   \n",
       "191  What have you learnt about where you are now, ...   \n",
       "192  · What do we want to talk about to look forwar...   \n",
       "193  How will you use what have you learnt about  y...   \n",
       "194  What steps can you think of taking from this l...   \n",
       "195  How will your current learning help you look a...   \n",
       "196  Please feel free to share what yiu eperince, t...   \n",
       "197     What lies beyond your outcome in this session?   \n",
       "198  I observe you saying ..., is this what you thi...   \n",
       "199  What have you learnt about yourself from the o...   \n",
       "200  What I sense is tht you .. .......how would yo...   \n",
       "201  How will you use what have you learnt about yo...   \n",
       "202  How will you act upon what have you learnt abo...   \n",
       "203  How will you use what have you learnt about yo...   \n",
       "204  Please feel free to share what yiu feel, this ...   \n",
       "205  · What do you seek aim for as an outcome or go...   \n",
       "206    What do you have on your mind to discuss today?   \n",
       "207  I am curious to know that based on what is hap...   \n",
       "208  What do you see as issues you may need help wi...   \n",
       "209  What I notice is tht you .. .......how would y...   \n",
       "210  · What do you to talk about to aim for as an o...   \n",
       "211  What I think is tht you .. .......how would yo...   \n",
       "212  What do you learn about where you are now, fro...   \n",
       "213    How are you able to align with your inner self?   \n",
       "214  How will ......this help you to look at yourr ...   \n",
       "\n",
       "                                      Free_format_Desc  \n",
       "0                  youwe want aim outcome goal session  \n",
       "1               want talk achieve outcome goal session  \n",
       "2                      help look situation differently  \n",
       "3       help look yourr future life after achieve want  \n",
       "4                                     hear feel happen  \n",
       "5                 seek accomplish outcome goal session  \n",
       "6                                   learn conversation  \n",
       "7             desire look forward outcome goal session  \n",
       "8                want discuss aim outcome goal session  \n",
       "9           use learn situation partner discusions far  \n",
       "10                                 value lead feel way  \n",
       "11           hear use word etc expression change sense  \n",
       "12                                                want  \n",
       "13      current insights help look youself differently  \n",
       "14                                                time  \n",
       "15                          learn share discusions far  \n",
       "16            coach question opne not force yes answer  \n",
       "17                        acknowledge progress journey  \n",
       "18                              like like move forward  \n",
       "19              learn situation partner discusions far  \n",
       "20                                            like say  \n",
       "21         current insights help look life differently  \n",
       "22                          learn share discusions far  \n",
       "23                awarenes abilities after exploration  \n",
       "24      want discuss look forward outcome goal session  \n",
       "25   high motivation give importance place on outco...  \n",
       "26                                    relate situation  \n",
       "27                act upon learn situation inquiry far  \n",
       "28                                               think  \n",
       "29                   awareness value after exploration  \n",
       "..                                                 ...  \n",
       "185                                               feel  \n",
       "186                                       wish achieve  \n",
       "187        current insights help look life differently  \n",
       "188         act upon learn current reality inquiry far  \n",
       "189                              hear tht like respond  \n",
       "190                      seek aim outcome goal session  \n",
       "191                       learn partner discusions far  \n",
       "192        want talk look forward outcome goal session  \n",
       "193               use learn situation conversation far  \n",
       "194                              step think take learn  \n",
       "195        current learn help look youself differently  \n",
       "196    please feel free share yiu eperince asafe space  \n",
       "197                         lie beyond outcome session  \n",
       "198                                  observe say think  \n",
       "199                         learn share discusions far  \n",
       "200                             sense tht like respond  \n",
       "201          use learn current reality exploration far  \n",
       "202                act upon learn share discusions far  \n",
       "203         use learn current reality conversation far  \n",
       "204        please feel free share yiu feel asafe space  \n",
       "205                      seek aim outcome goal session  \n",
       "206                              on mind discuss today  \n",
       "207                        curious know base on happen  \n",
       "208                             issue need help action  \n",
       "209                            notice tht like respond  \n",
       "210                      talk aim outcome goal session  \n",
       "211                             think tht like respond  \n",
       "212                             learn conversation far  \n",
       "213                              able align inner self  \n",
       "214     help look yourr future work after achieve want  \n",
       "\n",
       "[215 rows x 2 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3.1\n",
       "1      3.1\n",
       "2      7.4\n",
       "3      7.5\n",
       "4      4.2\n",
       "5      3.1\n",
       "6      7.1\n",
       "7      3.1\n",
       "8      3.1\n",
       "9      8.3\n",
       "10     7.2\n",
       "11     7.7\n",
       "12     7.2\n",
       "13     7.3\n",
       "14     4.3\n",
       "15     8.1\n",
       "16     7.6\n",
       "17     8.9\n",
       "18     NaN\n",
       "19     8.2\n",
       "20     4.3\n",
       "21     7.4\n",
       "22     8.2\n",
       "23     8.1\n",
       "24     3.1\n",
       "25     8.7\n",
       "26     5.4\n",
       "27     8.3\n",
       "28     7.2\n",
       "29     8.1\n",
       "      ... \n",
       "185    7.2\n",
       "186    3.1\n",
       "187    7.5\n",
       "188    8.3\n",
       "189    7.8\n",
       "190    3.1\n",
       "191    8.2\n",
       "192    3.1\n",
       "193    8.3\n",
       "194    8.5\n",
       "195    7.3\n",
       "196    4.2\n",
       "197    7.5\n",
       "198    6.6\n",
       "199    8.1\n",
       "200    7.8\n",
       "201    8.3\n",
       "202    8.3\n",
       "203    8.3\n",
       "204    4.2\n",
       "205    3.1\n",
       "206    3.1\n",
       "207    5.4\n",
       "208    8.6\n",
       "209    7.8\n",
       "210    3.1\n",
       "211    7.8\n",
       "212    8.2\n",
       "213    8.1\n",
       "214    7.5\n",
       "Name: Sub_markers, Length: 215, dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
