{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Marker auto-detection\n",
    "#### Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data loading and plotting packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model metric packages \n",
    "#from sklearn import cross_validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,roc_curve, auc\n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Text pre-processing packages \n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the root data into the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308, 2)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_data=pd.read_csv('E:\\All accumulated folder\\FREELANCE\\clean data\\Assesment File_v1.csv', encoding = 'unicode_escape')\n",
    "root_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversations</th>\n",
       "      <th>Sub_markers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I acknowledge the progress we made in this jou...</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I acknowledge the progress I made in this jour...</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I would like to appreciate your exploration to...</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How would you like acknowledge yourself before...</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If we have covered all you wanted to achieve a...</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Conversations  Sub_markers\n",
       "0  I acknowledge the progress we made in this jou...          8.9\n",
       "1  I acknowledge the progress I made in this jour...          8.9\n",
       "2  I would like to appreciate your exploration to...          8.9\n",
       "3  How would you like acknowledge yourself before...          8.9\n",
       "4  If we have covered all you wanted to achieve a...          8.8"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1    69\n",
       "8.3    40\n",
       "8.2    30\n",
       "8.1    26\n",
       "7.2    16\n",
       "6.6    13\n",
       "8.6    10\n",
       "7.1    10\n",
       "7.7     9\n",
       "8.5     9\n",
       "5.4     7\n",
       "7.5     6\n",
       "7.8     6\n",
       "7.4     5\n",
       "8.7     5\n",
       "7.3     5\n",
       "5.2     5\n",
       "8.4     5\n",
       "7.6     5\n",
       "8.9     4\n",
       "4.3     4\n",
       "4.2     4\n",
       "6.7     4\n",
       "8.8     3\n",
       "5.5     3\n",
       "4.4     2\n",
       "7.9     1\n",
       "6.8     1\n",
       "Name: Sub_markers, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(root_data)\n",
    "\n",
    "root_data[\"Sub_markers\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removing the missing values from free format description\n",
    "\n",
    "root_data=root_data[root_data[\"Conversations\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_data = root_data.astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -----------------------------------------------------------------Text Data  Pre-processing-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Removal of punctuations and special characteristics and handling case senitivity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Removal of Special Characters and Punctuations \n",
    "root_data['Free_format_Desc'] = root_data['Conversations'] .str.replace('[^\\w\\s]','')\n",
    "\n",
    "# converting into lower case \n",
    "root_data['Free_format_Desc'] = root_data['Free_format_Desc'].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i acknowledge the progress we made in this jou...\n",
       "1    i acknowledge the progress i made in this journey\n",
       "2    i would like to appreciate your exploration to...\n",
       "3    how would you like acknowledge yourself before...\n",
       "4    if we have covered all you wanted to achieve a...\n",
       "5    if we have covered all you wanted to do today ...\n",
       "6                       are ready to close the session\n",
       "7    who may the be the people you can turn to for ...\n",
       "8    what else is coming up as being helpful for yo...\n",
       "9    what do you see as issues you may need help wi...\n",
       "Name: Free_format_Desc, dtype: object"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text before stopword removal and handling abbrevations \n",
    "root_data['Free_format_Desc'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i acknowledge the progress we made in this jou...\n",
       "1    i acknowledge the progress i made in this journey\n",
       "2    i would like to appreciate your exploration to...\n",
       "Name: Free_format_Desc, dtype: object"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_data['Free_format_Desc'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversations</th>\n",
       "      <th>Sub_markers</th>\n",
       "      <th>Free_format_Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I acknowledge the progress we made in this jou...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>i acknowledge the progress we made in this jou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I acknowledge the progress I made in this jour...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>i acknowledge the progress i made in this journey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I would like to appreciate your exploration to...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>i would like to appreciate your exploration to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How would you like acknowledge yourself before...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>how would you like acknowledge yourself before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If we have covered all you wanted to achieve a...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>if we have covered all you wanted to achieve a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>If we have covered all you wanted to do today ...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>if we have covered all you wanted to do today ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Are ready to close the session?</td>\n",
       "      <td>8.8</td>\n",
       "      <td>are ready to close the session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Who may the be the people you can turn to for ...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>who may the be the people you can turn to for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What else is coming up as being helpful for yo...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>what else is coming up as being helpful for yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What do you see as issues you may need help wi...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>what do you see as issues you may need help wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What do you see as issues you may need help wi...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>what do you see as issues you may need help wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What do you think as issues you may need help ...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>what do you think as issues you may need help ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What do you think as issues you may need help ...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>what do you think as issues you may need help ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What do you anticipate as issues you may need ...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>what do you anticipate as issues you may need ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What do you anticipate as issues you may need ...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>what do you anticipate as issues you may need ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>As you reflect on actions you wish to take and...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>as you reflect on actions you wish to take and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>As you reflect on actions you wish to take and...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>as you reflect on actions you wish to take and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>With the high motivation you have given the im...</td>\n",
       "      <td>8.7</td>\n",
       "      <td>with the high motivation you have given the im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>With the high motivation you have given the im...</td>\n",
       "      <td>8.7</td>\n",
       "      <td>with the high motivation you have given the im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>With the high motivation you have given the im...</td>\n",
       "      <td>8.7</td>\n",
       "      <td>with the high motivation you have given the im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>With the high motivation you have given the im...</td>\n",
       "      <td>8.7</td>\n",
       "      <td>with the high motivation you have given the im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>With the high motivation you have given the im...</td>\n",
       "      <td>8.7</td>\n",
       "      <td>with the high motivation you have given the im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Let us see what comes up for you as actions to...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>let us see what comes up for you as actions to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>How may you consider acting on what you learn ...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>how may you consider acting on what you learn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>What steps can you think of taking from this r...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>what steps can you think of taking from this r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>What steps can you think of taking from this l...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>what steps can you think of taking from this l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>From when will you start applying what you hav...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>from when will you start applying what you hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>From when will you start applying what you hav...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>from when will you start applying what you hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>What else do you plan of doing?</td>\n",
       "      <td>8.5</td>\n",
       "      <td>what else do you plan of doing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What else do oyu think of doing?</td>\n",
       "      <td>8.5</td>\n",
       "      <td>what else do oyu think of doing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>What would help you to discuss about today</td>\n",
       "      <td>3.1</td>\n",
       "      <td>what would help you to discuss about today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>What would help you to talk about today</td>\n",
       "      <td>3.1</td>\n",
       "      <td>what would help you to talk about today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>So, this ",
       ".is what you wish to seek</td>\n",
       "      <td>3.1</td>\n",
       "      <td>so this is what you wish to seek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>So, this ",
       ".is what you wish to desire</td>\n",
       "      <td>3.1</td>\n",
       "      <td>so this is what you wish to desire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>So, this ",
       ".is what you wish to talk about</td>\n",
       "      <td>3.1</td>\n",
       "      <td>so this is what you wish to talk about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>So, this ",
       ".is what you wish to achieve</td>\n",
       "      <td>3.1</td>\n",
       "      <td>so this is what you wish to achieve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>So, this ",
       ".is what you wish to accomplish</td>\n",
       "      <td>3.1</td>\n",
       "      <td>so this is what you wish to accomplish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Feel free to tell me if my  understanding of w...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>feel free to tell me if my understanding of wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Please correct me if I am wrong</td>\n",
       "      <td>4.4</td>\n",
       "      <td>please correct me if i am wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>What else would you like to say</td>\n",
       "      <td>4.3</td>\n",
       "      <td>what else would you like to say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>What more would you like to say</td>\n",
       "      <td>4.3</td>\n",
       "      <td>what more would you like to say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Take your time...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>take your time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Is there anything more to add</td>\n",
       "      <td>4.3</td>\n",
       "      <td>is there anything more to add</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>I hear your feeling ....... about what is happ...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>i hear your feeling about what is happening to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Please feel free to share what yiu feel, this ...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>please feel free to share what yiu feel this i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Please feel free to share what yiu think, this...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>please feel free to share what yiu think this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Please feel free to share what yiu eperince, t...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>please feel free to share what yiu eperince th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>I hear you saying ..., is this what you think ...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>i hear you saying is this what you think of yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>I observe you saying ..., is this what you thi...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>i observe you saying is this what you think of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>I notice you saying ..., is this what you thin...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>i notice you saying is this what you think of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>I hear you saying ..., is this what you think ...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>i hear you saying is this what you think of ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>I observe you saying ..., is this what you thi...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>i observe you saying is this what you think of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>I  notice you saying ..., is this what you thi...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>i notice you saying is this what you think of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>I hear you saying ..., is this what you think ...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>i hear you saying is this what you think of yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>I observe you saying ..., is this what you thi...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>i observe you saying is this what you think of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>I notice you saying ..., is this what you thin...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>i notice you saying is this what you think of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>What would make you think of others around you...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>what would make you think of others around you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>What would make you think of  your  workplace....</td>\n",
       "      <td>6.6</td>\n",
       "      <td>what would make you think of your workplace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>What would make you feel difffrently of yourse...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>what would make you feel difffrently of yourse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>What would make you feel difffrently of yourse...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>what would make you feel difffrently of yourse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>308 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Conversations Sub_markers  \\\n",
       "0    I acknowledge the progress we made in this jou...         8.9   \n",
       "1    I acknowledge the progress I made in this jour...         8.9   \n",
       "2    I would like to appreciate your exploration to...         8.9   \n",
       "3    How would you like acknowledge yourself before...         8.9   \n",
       "4    If we have covered all you wanted to achieve a...         8.8   \n",
       "5    If we have covered all you wanted to do today ...         8.8   \n",
       "6                      Are ready to close the session?         8.8   \n",
       "7    Who may the be the people you can turn to for ...         8.6   \n",
       "8    What else is coming up as being helpful for yo...         8.6   \n",
       "9    What do you see as issues you may need help wi...         8.6   \n",
       "10   What do you see as issues you may need help wi...         8.6   \n",
       "11   What do you think as issues you may need help ...         8.6   \n",
       "12   What do you think as issues you may need help ...         8.6   \n",
       "13   What do you anticipate as issues you may need ...         8.6   \n",
       "14   What do you anticipate as issues you may need ...         8.6   \n",
       "15   As you reflect on actions you wish to take and...         8.6   \n",
       "16   As you reflect on actions you wish to take and...         8.6   \n",
       "17   With the high motivation you have given the im...         8.7   \n",
       "18   With the high motivation you have given the im...         8.7   \n",
       "19   With the high motivation you have given the im...         8.7   \n",
       "20   With the high motivation you have given the im...         8.7   \n",
       "21   With the high motivation you have given the im...         8.7   \n",
       "22   Let us see what comes up for you as actions to...         8.5   \n",
       "23   How may you consider acting on what you learn ...         8.5   \n",
       "24   What steps can you think of taking from this r...         8.5   \n",
       "25   What steps can you think of taking from this l...         8.5   \n",
       "26   From when will you start applying what you hav...         8.5   \n",
       "27   From when will you start applying what you hav...         8.5   \n",
       "28                     What else do you plan of doing?         8.5   \n",
       "29                    What else do oyu think of doing?         8.5   \n",
       "..                                                 ...         ...   \n",
       "278         What would help you to discuss about today         3.1   \n",
       "279            What would help you to talk about today         3.1   \n",
       "280                So, this \n",
       ".is what you wish to seek         3.1   \n",
       "281              So, this \n",
       ".is what you wish to desire         3.1   \n",
       "282          So, this \n",
       ".is what you wish to talk about         3.1   \n",
       "283             So, this \n",
       ".is what you wish to achieve         3.1   \n",
       "284          So, this \n",
       ".is what you wish to accomplish         3.1   \n",
       "285  Feel free to tell me if my  understanding of w...         4.4   \n",
       "286                    Please correct me if I am wrong         4.4   \n",
       "287                    What else would you like to say         4.3   \n",
       "288                    What more would you like to say         4.3   \n",
       "289                                  Take your time...         4.3   \n",
       "290                     Is there anything more to add          4.3   \n",
       "291  I hear your feeling ....... about what is happ...         4.2   \n",
       "292  Please feel free to share what yiu feel, this ...         4.2   \n",
       "293  Please feel free to share what yiu think, this...         4.2   \n",
       "294  Please feel free to share what yiu eperince, t...         4.2   \n",
       "295  I hear you saying ..., is this what you think ...         6.6   \n",
       "296  I observe you saying ..., is this what you thi...         6.6   \n",
       "297  I notice you saying ..., is this what you thin...         6.6   \n",
       "298  I hear you saying ..., is this what you think ...         6.6   \n",
       "299  I observe you saying ..., is this what you thi...         6.6   \n",
       "300  I  notice you saying ..., is this what you thi...         6.6   \n",
       "301  I hear you saying ..., is this what you think ...         6.6   \n",
       "302  I observe you saying ..., is this what you thi...         6.6   \n",
       "303  I notice you saying ..., is this what you thin...         6.6   \n",
       "304  What would make you think of others around you...         6.6   \n",
       "305  What would make you think of  your  workplace....         6.6   \n",
       "306  What would make you feel difffrently of yourse...         6.6   \n",
       "307  What would make you feel difffrently of yourse...         6.6   \n",
       "\n",
       "                                      Free_format_Desc  \n",
       "0    i acknowledge the progress we made in this jou...  \n",
       "1    i acknowledge the progress i made in this journey  \n",
       "2    i would like to appreciate your exploration to...  \n",
       "3    how would you like acknowledge yourself before...  \n",
       "4    if we have covered all you wanted to achieve a...  \n",
       "5    if we have covered all you wanted to do today ...  \n",
       "6                       are ready to close the session  \n",
       "7    who may the be the people you can turn to for ...  \n",
       "8    what else is coming up as being helpful for yo...  \n",
       "9    what do you see as issues you may need help wi...  \n",
       "10   what do you see as issues you may need help wi...  \n",
       "11   what do you think as issues you may need help ...  \n",
       "12   what do you think as issues you may need help ...  \n",
       "13   what do you anticipate as issues you may need ...  \n",
       "14   what do you anticipate as issues you may need ...  \n",
       "15   as you reflect on actions you wish to take and...  \n",
       "16   as you reflect on actions you wish to take and...  \n",
       "17   with the high motivation you have given the im...  \n",
       "18   with the high motivation you have given the im...  \n",
       "19   with the high motivation you have given the im...  \n",
       "20   with the high motivation you have given the im...  \n",
       "21   with the high motivation you have given the im...  \n",
       "22   let us see what comes up for you as actions to...  \n",
       "23   how may you consider acting on what you learn ...  \n",
       "24   what steps can you think of taking from this r...  \n",
       "25   what steps can you think of taking from this l...  \n",
       "26   from when will you start applying what you hav...  \n",
       "27   from when will you start applying what you hav...  \n",
       "28                      what else do you plan of doing  \n",
       "29                     what else do oyu think of doing  \n",
       "..                                                 ...  \n",
       "278         what would help you to discuss about today  \n",
       "279            what would help you to talk about today  \n",
       "280                   so this is what you wish to seek  \n",
       "281                 so this is what you wish to desire  \n",
       "282             so this is what you wish to talk about  \n",
       "283                so this is what you wish to achieve  \n",
       "284             so this is what you wish to accomplish  \n",
       "285  feel free to tell me if my understanding of wh...  \n",
       "286                    please correct me if i am wrong  \n",
       "287                    what else would you like to say  \n",
       "288                    what more would you like to say  \n",
       "289                                     take your time  \n",
       "290                      is there anything more to add  \n",
       "291  i hear your feeling about what is happening to...  \n",
       "292  please feel free to share what yiu feel this i...  \n",
       "293  please feel free to share what yiu think this ...  \n",
       "294  please feel free to share what yiu eperince th...  \n",
       "295  i hear you saying is this what you think of yo...  \n",
       "296  i observe you saying is this what you think of...  \n",
       "297  i notice you saying is this what you think of ...  \n",
       "298  i hear you saying is this what you think of ot...  \n",
       "299  i observe you saying is this what you think of...  \n",
       "300  i notice you saying is this what you think of ...  \n",
       "301  i hear you saying is this what you think of yo...  \n",
       "302  i observe you saying is this what you think of...  \n",
       "303  i notice you saying is this what you think of ...  \n",
       "304     what would make you think of others around you  \n",
       "305        what would make you think of your workplace  \n",
       "306  what would make you feel difffrently of yourse...  \n",
       "307  what would make you feel difffrently of yourse...  \n",
       "\n",
       "[308 rows x 3 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -----------------------------------------------------------------------End of Text Data  Pre-Processing------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversations</th>\n",
       "      <th>Free_format_Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>· What do you want to discuss to aim for as an...</td>\n",
       "      <td>what do you want to discuss to aim for as an o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Conversations  \\\n",
       "254  · What do you want to discuss to aim for as an...   \n",
       "\n",
       "                                      Free_format_Desc  \n",
       "254  what do you want to discuss to aim for as an o...  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_data= root_data.drop(\"Sub_markers\",axis=1)\n",
    "y_data= root_data[\"Sub_markers\"]\n",
    "y_data.reset_index(inplace=True,drop=True)\n",
    "X, X_test, y, y_test = train_test_split(X_data, y_data, test_size=0.2, train_size=0.8)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size = 0.25,train_size =0.75)\n",
    "X_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      8.9\n",
       "1      8.9\n",
       "2      8.9\n",
       "3      8.9\n",
       "4      8.8\n",
       "5      8.8\n",
       "6      8.8\n",
       "7      8.6\n",
       "8      8.6\n",
       "9      8.6\n",
       "10     8.6\n",
       "11     8.6\n",
       "12     8.6\n",
       "13     8.6\n",
       "14     8.6\n",
       "15     8.6\n",
       "16     8.6\n",
       "17     8.7\n",
       "18     8.7\n",
       "19     8.7\n",
       "20     8.7\n",
       "21     8.7\n",
       "22     8.5\n",
       "23     8.5\n",
       "24     8.5\n",
       "25     8.5\n",
       "26     8.5\n",
       "27     8.5\n",
       "28     8.5\n",
       "29     8.5\n",
       "      ... \n",
       "278    3.1\n",
       "279    3.1\n",
       "280    3.1\n",
       "281    3.1\n",
       "282    3.1\n",
       "283    3.1\n",
       "284    3.1\n",
       "285    4.4\n",
       "286    4.4\n",
       "287    4.3\n",
       "288    4.3\n",
       "289    4.3\n",
       "290    4.3\n",
       "291    4.2\n",
       "292    4.2\n",
       "293    4.2\n",
       "294    4.2\n",
       "295    6.6\n",
       "296    6.6\n",
       "297    6.6\n",
       "298    6.6\n",
       "299    6.6\n",
       "300    6.6\n",
       "301    6.6\n",
       "302    6.6\n",
       "303    6.6\n",
       "304    6.6\n",
       "305    6.6\n",
       "306    6.6\n",
       "307    6.6\n",
       "Name: Sub_markers, Length: 308, dtype: object"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pre process text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SRABANTI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SRABANTI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as n\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "REPLACE_IP_ADDRESS = re.compile(r'\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b')\n",
    "\n",
    "def text_prepare(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.replace('\\n', ' ').lower()# lowercase text\n",
    "    text = REPLACE_IP_ADDRESS.sub('', text)\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ',text)# replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('',text)# delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join([w for w in text.split() if not w in STOPWORDS])# delete stopwords from text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionary of all words from train corpus with their counts.\n",
    "words_counts = {}\n",
    "for comments in X_train:\n",
    "    for word in comments.split():\n",
    "        if word not in words_counts:\n",
    "            words_counts[word] = 1\n",
    "        words_counts[word] += 1\n",
    "        \n",
    "DICT_SIZE = 10000\n",
    "POPULAR_WORDS = sorted(words_counts, key=words_counts.get, reverse=True)[:DICT_SIZE]\n",
    "WORDS_TO_INDEX = {key: rank for rank, key in enumerate(POPULAR_WORDS, 0)}\n",
    "INDEX_TO_WORDS = {index:word for word, index in WORDS_TO_INDEX.items()}\n",
    "ALL_WORDS = WORDS_TO_INDEX.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Conversations', 'Free_format_Desc']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets take a look at top 10 popular words\n",
    "POPULAR_WORDS[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse as sp_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape  (2, 10000) \n",
      "X_val shape  (2, 10000)\n"
     ]
    }
   ],
   "source": [
    "def my_bag_of_words(text, words_to_index, dict_size):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        dict_size: size of the dictionary\n",
    "        \n",
    "        return a vector which is a bag-of-words representation of 'text'\n",
    "    \"\"\"\n",
    "    result_vector = np.zeros(dict_size)\n",
    "    for word in text.split(' '):\n",
    "        if word in words_to_index:\n",
    "            result_vector[words_to_index[word]] +=1\n",
    "    return result_vector\n",
    "\n",
    "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train])\n",
    "X_val_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_val])\n",
    "print('X_train shape ', X_train_mybag.shape, '\\nX_val shape ', X_val_mybag.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_features(X_train, X_val, X_test):\n",
    "    \"\"\"\n",
    "        X_train, X_test — samples        \n",
    "        return TF-IDF vectorized representation of each sample and vocabulary\n",
    "    \"\"\"\n",
    "    # Create TF-IDF vectorizer with a proper parameters choice\n",
    "    # Fit the vectorizer on the train set\n",
    "    # Transform the train, test set and return the result\n",
    "    \n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=1.0, min_df=1, token_pattern='(\\S+)')\n",
    "\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "    return X_train_tfidf, X_val_tfidf, X_test_tfidf, tfidf_vectorizer.vocabulary_\n",
    "\n",
    "X_train_tfidf, X_val_tfidf, X_test_tfidf, tfidf_vocab = tfidf_features(X_train, X_val, X_test)\n",
    "tfidf_reversed_vocab = {i:word for word,i in tfidf_vocab.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (254    3.1\n171    7.4\n170    7.4\n153    7.2\n133    6.7\n150    7.2\n291    4.2\n214    5.4\n65     8.3\n164    7.3\n212    5.4\n129    8.2\n23     8.5\n301    6.6\n253    3.1\n251    3.1\n169    7.4\n143    7.1\n282    3.1\n262    3.1\n152    7.2\n217    3.1\n306    6.6\n185    7.7\n189    7.7\n25     8.5\n27     8.5\n160    7.2\n183    7.7\n278    3.1\n      ... \n295    6.6\n272    3.1\n249    3.1\n222    3.1\n264    3.1\n245    3.1\n241    3.1\n205    NaN\n146    7.2\n51     8.1\n266    3.1\n204    5.2\n144    7.1\n283    3.1\n273    3.1\n211    5.4\n93     8.3\n45     8.1\n293    4.2\n56     8.1\n255    3.1\n29     8.5\n62     8.3\n236    3.1\n73     8.3\n115    8.2\n297    6.6\n268    3.1\n256    3.1\n118    8.2\nName: Sub_markers, Length: 184, dtype: object,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-161-8db9f13c1857>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mclassifier_mybag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_mybag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregularisation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'l2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mclassifier_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregularisation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'l2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-161-8db9f13c1857>\u001b[0m in \u001b[0;36mtrain_classifier\u001b[1;34m(X_train, y_train, C, regularisation)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Create and fit LogisticRegression wraped into OneVsRestClassifier.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregularisation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;31m# overall.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mShape\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0mproblems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \"\"\"\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_input_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: (254    3.1\n171    7.4\n170    7.4\n153    7.2\n133    6.7\n150    7.2\n291    4.2\n214    5.4\n65     8.3\n164    7.3\n212    5.4\n129    8.2\n23     8.5\n301    6.6\n253    3.1\n251    3.1\n169    7.4\n143    7.1\n282    3.1\n262    3.1\n152    7.2\n217    3.1\n306    6.6\n185    7.7\n189    7.7\n25     8.5\n27     8.5\n160    7.2\n183    7.7\n278    3.1\n      ... \n295    6.6\n272    3.1\n249    3.1\n222    3.1\n264    3.1\n245    3.1\n241    3.1\n205    NaN\n146    7.2\n51     8.1\n266    3.1\n204    5.2\n144    7.1\n283    3.1\n273    3.1\n211    5.4\n93     8.3\n45     8.1\n293    4.2\n56     8.1\n255    3.1\n29     8.5\n62     8.3\n236    3.1\n73     8.3\n115    8.2\n297    6.6\n268    3.1\n256    3.1\n118    8.2\nName: Sub_markers, Length: 184, dtype: object,)"
     ]
    }
   ],
   "source": [
    "def train_classifier(X_train, y_train, C, regularisation):\n",
    "    \"\"\"\n",
    "      X_train, y_train — training data\n",
    "      \n",
    "      return: trained classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create and fit LogisticRegression wraped into OneVsRestClassifier.\n",
    "\n",
    "    model = OneVsRestClassifier(LogisticRegression(penalty=regularisation, C=C, max_iter=10000)).fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "classifier_mybag = train_classifier(X_train_mybag, y_train, C = 4, regularisation = 'l2')\n",
    "classifier_tfidf = train_classifier(X_train_tfidf, y_train, C = 4, regularisation = 'l2')\n",
    "\n",
    "y_val_predicted_labels_mybag = classifier_mybag.predict(X_val_mybag)\n",
    "y_val_predicted_labels_tfidf = classifier_tfidf.predict(X_val_tfidf)\n",
    "y_val_predicted_scores_mybag = classifier_mybag.decision_function(X_val_mybag)\n",
    "y_val_predicted_scores_tfidf = classifier_tfidf.decision_function(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_evaluation_scores(y_test, predicted):\n",
    "    \n",
    "    print('Accuracy: ', accuracy_score(y_test, predicted, normalize=False))\n",
    "    print('F1-score macro: ', f1_score(y_test, predicted, average='macro'))\n",
    "    print('F1-score micro: ', f1_score(y_test, predicted, average='micro'))\n",
    "    print('F1-score weighted: ', f1_score(y_test, predicted, average='weighted'))\n",
    "    print('Precision macro: ', average_precision_score(y_test, predicted, average='macro'))\n",
    "    print('Precision micro: ', average_precision_score(y_test, predicted, average='micro'))\n",
    "    print('Precision weighted: ', average_precision_score(y_test, predicted, average='weighted'))\n",
    "    \n",
    "print('Bag-of-words\\n')\n",
    "print_evaluation_scores(y_val, y_val_predicted_labels_mybag)\n",
    "print('\\nTfidf\\n')\n",
    "print_evaluation_scores(y_val, y_val_predicted_labels_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions = classifier_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pred_labels(data, predictions):\n",
    "    y_cols = list(data.columns[2:])\n",
    "    y_label_dict={}\n",
    "    for k,v in enumerate(y_cols):\n",
    "        y_label_dict[k] = v\n",
    "\n",
    "    test_predictions_labels = []\n",
    "    for pred in predictions:\n",
    "        label_pred = []\n",
    "        for index, label in enumerate(list(pred)):\n",
    "            if label != 0:\n",
    "                label = y_label_dict[index]\n",
    "            label_pred.append(label)\n",
    "        test_predictions_labels.append(tuple([i for i in label_pred if i != 0]))\n",
    "    return test_predictions_labels\n",
    "\n",
    "test_pred_labels = get_pred_labels(data, test_predictions)\n",
    "test_labels = get_pred_labels(data, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(90,97):\n",
    "    print('\\ny_label: ', test_labels[i], '\\ny_pred: ', test_pred_labels[i])\n",
    "print('\\ny_label: ', test_labels[i], '\\ny_pred: ', test_pred_labels[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
